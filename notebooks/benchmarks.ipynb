{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e586398d",
   "metadata": {},
   "source": [
    "##### calculating training time benchmarks for various samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "trees = pd.read_csv('../data/raw/new_york_tree_census_2015.csv')\n",
    "# print(trees.columns)\n",
    "\n",
    "target = trees['health']\n",
    "keep_rows = target.notna()\n",
    "\n",
    "drop_cols = ['health','tree_id', 'block_id', 'created_at', 'stump_diam','status','spc_common','problems','address',\\\n",
    "             'zip_city','cb_num', 'borocode', 'cncldist', 'st_assem', 'st_senate', 'nta', 'boro_ct', 'state',\\\n",
    "             'latitude', 'longitude']\n",
    "\n",
    "group = ['nta_name']\n",
    "spatial_geo = ['x_sp','y_sp'] # encode numerical, standardize\n",
    "spatial_fine = ['zipcode'] # encode categorical\n",
    "spatial_coarse = ['boroname'] # encode categorical\n",
    "\n",
    "## base ftrs, without spatial ##\n",
    "numerical_ftrs = ['tree_dbh']\n",
    "categorical_ftrs = ['curb_loc', 'spc_latin', 'user_type', 'root_stone',\n",
    "                    'root_grate', 'root_other', 'trunk_wire', 'trnk_light', 'trnk_other',\n",
    "                    'brch_light', 'brch_shoe', 'brch_other']\n",
    "ordinal_ftrs = ['steward','guards','sidewalk']\n",
    "ordinal_cats = [['None','1or2','3or4','4orMore'],\n",
    "                ['None','Harmful','Unsure','Helpful'],\n",
    "                ['Damage','None','NoDamage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50096828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we have accounted for all columns\n",
    "listed = set(drop_cols).union(group,spatial_geo,spatial_fine,spatial_coarse,\\\n",
    "                              numerical_ftrs,categorical_ftrs,ordinal_ftrs)\n",
    "print(set(trees.columns).difference(listed) == set())\n",
    "# handle ordinal ftrs to fill in na\n",
    "for ftr in ordinal_ftrs:\n",
    "    trees[ftr] = trees[ftr].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## DATA SAMPLING ##\n",
    "RANDOM_STATE = 1\n",
    "# define feature sets\n",
    "drop_cols_set = drop_cols + group # + spatial_fine + spatial_coarse\n",
    "categorical_ftrs_set = categorical_ftrs + spatial_fine + spatial_coarse\n",
    "numerical_ftrs_set = numerical_ftrs + spatial_geo\n",
    "\n",
    "y = target[keep_rows]\n",
    "X = trees[keep_rows].drop(drop_cols_set, axis=1)\n",
    "groups = trees[keep_rows][group]\n",
    "\n",
    "def get_sample(X, y, groups, prop, random_state):\n",
    "    SAMPLE_PROP = prop\n",
    "    RANDOM_STATE = random_state\n",
    "    ## hold out a test set by groups\n",
    "    gss_test = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    train_idx, test_idx = next(gss_test.split(X, y, groups))\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]\n",
    "    ## sample 10% for cross validation\n",
    "    X_sub, _, y_sub, _, groups_sub, _ = train_test_split(\n",
    "        X_train, y_train, groups_train,\n",
    "        train_size=SAMPLE_PROP,\n",
    "        stratify=y_train,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    return X_train, X_test, X_sub, \\\n",
    "           y_train, y_test, y_sub, \\\n",
    "           groups_train, groups_test, groups_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "a = [0,1,2,3,4,5,6,7]\n",
    "print(a[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proportions = [0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "y = target[keep_rows]\n",
    "X = trees[keep_rows].drop(drop_cols_set, axis=1)\n",
    "groups = trees[keep_rows][group]\n",
    "\n",
    "for prop in sample_proportions:\n",
    "    datas = get_sample(X, y, groups, prop=prop, random_state=1)\n",
    "    _, X_test, X_sub = datas[0:3]\n",
    "    _, y_test, y_sub = datas[3:6]\n",
    "    _, groups_test, groups_sub = datas[6:]\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree_census",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
