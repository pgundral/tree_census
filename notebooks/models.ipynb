{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b67e7aa",
   "metadata": {},
   "source": [
    "##### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97091d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "trees = pd.read_csv('../data/raw/new_york_tree_census_2015.csv')\n",
    "# print(trees.columns)\n",
    "\n",
    "target = trees['health']\n",
    "keep_rows = target.notna()\n",
    "\n",
    "drop_cols = ['health','tree_id', 'block_id', 'created_at', 'stump_diam','status','spc_common','problems','address',\\\n",
    "             'zip_city','cb_num', 'borocode', 'cncldist', 'st_assem', 'st_senate', 'nta', 'boro_ct', 'state',\\\n",
    "             'latitude', 'longitude']\n",
    "\n",
    "group = ['nta_name']\n",
    "spatial_geo = ['x_sp','y_sp'] # encode numerical, standardize\n",
    "spatial_fine = ['zipcode'] # encode categorical\n",
    "spatial_coarse = ['boroname'] # encode categorical\n",
    "\n",
    "## base ftrs, without spatial ##\n",
    "numerical_ftrs = ['tree_dbh']\n",
    "categorical_ftrs = ['curb_loc', 'spc_latin', 'user_type', 'root_stone',\n",
    "                    'root_grate', 'root_other', 'trunk_wire', 'trnk_light', 'trnk_other',\n",
    "                    'brch_light', 'brch_shoe', 'brch_other']\n",
    "ordinal_ftrs = ['steward','guards','sidewalk']\n",
    "ordinal_cats = [['None','1or2','3or4','4orMore'],\n",
    "                ['None','Harmful','Unsure','Helpful'],\n",
    "                ['Damage','None','NoDamage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead39663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check we have accounted for all columns\n",
    "listed = set(drop_cols).union(group,spatial_geo,spatial_fine,spatial_coarse,\\\n",
    "                              numerical_ftrs,categorical_ftrs,ordinal_ftrs)\n",
    "print(set(trees.columns).difference(listed) == set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8f7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle ordinal ftrs to fill in na\n",
    "for ftr in ordinal_ftrs:\n",
    "    trees[ftr] = trees[ftr].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## CROSS VALIDATION PIPELINE ##\n",
    "RANDOM_STATE = 1\n",
    "# define feature sets\n",
    "drop_cols_set = drop_cols + group # + spatial_fine + spatial_coarse\n",
    "categorical_ftrs_set = categorical_ftrs + spatial_fine + spatial_coarse\n",
    "numerical_ftrs_set = numerical_ftrs + spatial_geo\n",
    "\n",
    "# define a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories=ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), categorical_ftrs_set),\n",
    "        ('std', StandardScaler(), numerical_ftrs_set)])\n",
    "# define splitters\n",
    "# gkf = GroupKFold(n_splits=4,shuffle=True,random_state=RANDOM_STATE) # not using gkf due to time constraint\n",
    "gss = GroupShuffleSplit(n_splits=1,random_state=RANDOM_STATE)\n",
    "# define algo\n",
    "algo = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000)\n",
    "# make pipeline\n",
    "pipe = make_pipeline(preprocessor,algo)\n",
    "# define params\n",
    "param_grid = {\n",
    "            'logisticregression__C': [0.01, 0.1, 1, 10], \n",
    "            'logisticregression__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'logisticregression__random_state': [RANDOM_STATE]\n",
    "            }\n",
    "# make grid\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid=param_grid, \n",
    "    scoring='f1_macro',\n",
    "    cv=gss,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    refit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f61b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SAMPLING #\n",
    "SAMPLE_PROP = 0.05\n",
    "y = target[keep_rows]\n",
    "X = trees[keep_rows].drop(drop_cols_set, axis=1)\n",
    "groups = trees[keep_rows][group]\n",
    "## hold out a test set by groups\n",
    "gss_test = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss_test.split(X, y, groups))\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]\n",
    "## sample 10% for cross validation\n",
    "X_sub, _, y_sub, _, groups_sub, _ = train_test_split(\n",
    "    X_train, y_train, groups_train,\n",
    "    train_size=SAMPLE_PROP,\n",
    "    stratify=y_train,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce4c40",
   "metadata": {},
   "source": [
    "```python\n",
    "# testing different hyperparameters\n",
    "random_states = [1,33,42,44,99]\n",
    "results = []\n",
    "for rs in random_states:\n",
    "    gss = GroupShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000)\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'logisticregression__C': [0.01, 0.1, 1, 10], \n",
    "            'logisticregression__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'logisticregression__random_state': [rs]\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        refit=False\n",
    "    )\n",
    "    grid.fit(X_sub, y_sub, groups=groups_sub)\n",
    "    results.append(grid.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e9251",
   "metadata": {},
   "source": [
    "```python\n",
    "from json import dumps\n",
    "print(dumps(results,indent=4))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5086a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final hyperparameters\n",
    "# C = 10\n",
    "# l1_ratio = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4416d",
   "metadata": {},
   "source": [
    "#### cross validation on logistic regression with elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d392a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time=  38.2s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time=  39.4s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time=  42.7s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time=  44.0s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time=  45.9s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time=  46.8s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time=  51.0s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time=  54.1s\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 1.7min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 1.9min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 2.6min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 2.9min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 3.2min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 3.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 3.4min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 3.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 3.8min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 4.1min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 4.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 4.6min\n",
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 7.0min\n",
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 9.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 9.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 9.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time=10.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 9.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 9.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 9.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 9.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time=10.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 8.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 8.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 8.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 7.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 8.0min\n",
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 1.6min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 1.6min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 1.7min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 1.8min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 1.8min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 1.9min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 2.0min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 2.1min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 3.2min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 3.8min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 3.4min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 3.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 3.6min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 3.7min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 3.9min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 4.0min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 4.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 4.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 3.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.5min\n",
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 6.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 7.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 7.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=None, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 6.8min\n"
     ]
    }
   ],
   "source": [
    "# testing balanced vs None class_weights\n",
    "random_states = [1,99]\n",
    "results_scores = []\n",
    "results_params = []\n",
    "results_model = []\n",
    "for rs in random_states:\n",
    "    gss = GroupShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000)\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'logisticregression__C': [0.01, 0.1, 1, 10], \n",
    "            'logisticregression__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'logisticregression__class_weight': ['balanced', None],\n",
    "            'logisticregression__random_state': [rs]\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X_sub, y_sub, groups=groups_sub)\n",
    "    results_params.append(grid.best_params_)\n",
    "    results_scores.append(grid.cv_results_)\n",
    "    results_model.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b294b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.7,\n",
      "        \"logisticregression__random_state\": 1\n",
      "    },\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.5,\n",
      "        \"logisticregression__random_state\": 99\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from json import dumps\n",
    "print(dumps(results_params,indent=4))\n",
    "# print(results_scores)\n",
    "# print(results_model)\n",
    "\n",
    "# our best hyperparameters are:\n",
    "# C = 0.1, L1 = 0.5 or 0.7\n",
    "# class_weight = balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531cd18",
   "metadata": {},
   "source": [
    "##### cross validation on logistic regression: `stratified vs group`\n",
    "We train only on `'balanced'` class weights, but use all hyperparameter combos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2425: UserWarning: The groups parameter is ignored by StratifiedShuffleSplit\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 1.1min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 1.2min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 1.3min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 1.4min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 2.4min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 3.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 3.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 3.7min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 3.8min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 8.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 9.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 9.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 8.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 8.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 8.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 8.0min\n",
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2425: UserWarning: The groups parameter is ignored by StratifiedShuffleSplit\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 1.7min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 1.7min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 1.8min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 2.0min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 3.0min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 4.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 4.5min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 4.7min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 4.9min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 8.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 8.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 8.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 7.1min\n"
     ]
    }
   ],
   "source": [
    "# testing using random splitting instead of Group\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "random_states = [1,99]\n",
    "results_scores = []\n",
    "results_params = []\n",
    "results_model = []\n",
    "results_grid = []\n",
    "for rs in random_states:\n",
    "    gss = StratifiedShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000)\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'logisticregression__C': [0.01, 0.1, 1, 10], \n",
    "            'logisticregression__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'logisticregression__class_weight': ['balanced'],\n",
    "            'logisticregression__random_state': [rs]\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X_sub, y_sub)\n",
    "    results_params.append(grid.best_params_)\n",
    "    results_scores.append(grid.cv_results_)\n",
    "    results_model.append(grid.best_estimator_)\n",
    "    results_grid.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.3,\n",
      "        \"logisticregression__random_state\": 1\n",
      "    },\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.9,\n",
      "        \"logisticregression__random_state\": 99\n",
      "    }\n",
      "]\n",
      "C 0.1, l1 0.3: 0.37142152187216704\n",
      "C 0.1, l1 0.9: 0.3682450200379508\n"
     ]
    }
   ],
   "source": [
    "print(dumps(results_params,indent=4))\n",
    "# print(results_scores)\n",
    "cv_df = pd.DataFrame(results_scores[0])\n",
    "mask = (\n",
    "    (cv_df['param_logisticregression__C'] == 0.1) &\n",
    "    (cv_df['param_logisticregression__l1_ratio'] == 0.3) &\n",
    "    (cv_df['param_logisticregression__class_weight'] == 'balanced')\n",
    ")\n",
    "mean_test_score = cv_df.loc[mask, 'mean_test_score'].iloc[0]\n",
    "print(f'C 0.1, l1 0.3: {mean_test_score}')\n",
    "\n",
    "cv_df = pd.DataFrame(results_scores[1])\n",
    "mask = (\n",
    "    (cv_df['param_logisticregression__C'] == 0.1) &\n",
    "    (cv_df['param_logisticregression__l1_ratio'] == 0.9) &\n",
    "    (cv_df['param_logisticregression__class_weight'] == 'balanced')\n",
    ")\n",
    "mean_test_score = cv_df.loc[mask, 'mean_test_score'].iloc[0]\n",
    "print(f'C 0.1, l1 0.9: {mean_test_score}')\n",
    "\n",
    "# print(results_model)\n",
    "\n",
    "# our best hyperparameters are:\n",
    "# C = 0.1, L1 = 0.3\n",
    "# class_weight = balanced\n",
    "# shuffling = random\n",
    "# score = 0.37142152187216704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b34c9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 1.1min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 1.1min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 1.3min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 1.3min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 2.3min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 2.7min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 3.0min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 3.2min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 3.4min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 3.5min\n",
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 6.8min\n",
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 7.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 7.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=1; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=1; total time= 7.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=1; total time= 7.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=1; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=1; total time= 7.4min\n",
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 1.2min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 1.3min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 1.4min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 1.6min\n",
      "[CV] END logisticregression__C=0.01, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 2.7min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 3.1min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 3.2min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 3.6min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 3.8min\n",
      "[CV] END logisticregression__C=0.1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 6.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 7.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=1, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.1, logisticregression__random_state=99; total time= 6.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.3, logisticregression__random_state=99; total time= 6.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.5, logisticregression__random_state=99; total time= 6.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.7, logisticregression__random_state=99; total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tree_census/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logisticregression__C=10, logisticregression__class_weight=balanced, logisticregression__l1_ratio=0.9, logisticregression__random_state=99; total time= 6.4min\n"
     ]
    }
   ],
   "source": [
    "# GROUP\n",
    "random_states = [1,99]\n",
    "results_scores_g = []\n",
    "results_best_scores_g = []\n",
    "results_params_g = []\n",
    "results_model_g = []\n",
    "for rs in random_states:\n",
    "    gss = GroupShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000)\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'logisticregression__C': [0.01, 0.1, 1, 10], \n",
    "            'logisticregression__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'logisticregression__class_weight': ['balanced'],\n",
    "            'logisticregression__random_state': [rs]\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X_sub, y_sub, groups=groups_sub)\n",
    "    results_params_g.append(grid.best_params_)\n",
    "    results_scores_g.append(grid.cv_results_)\n",
    "    best_idx = grid.best_index_\n",
    "    best_val_score = grid.cv_results_['mean_test_score'][best_idx]\n",
    "    results_best_scores_g.append(best_val_score)\n",
    "    results_model_g.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.7,\n",
      "        \"logisticregression__random_state\": 1\n",
      "    },\n",
      "    {\n",
      "        \"logisticregression__C\": 0.1,\n",
      "        \"logisticregression__class_weight\": \"balanced\",\n",
      "        \"logisticregression__l1_ratio\": 0.5,\n",
      "        \"logisticregression__random_state\": 99\n",
      "    }\n",
      "]\n",
      "[np.float64(0.382426793855901), np.float64(0.35639615256770846)]\n"
     ]
    }
   ],
   "source": [
    "print(dumps(results_params_g,indent=4))\n",
    "print(results_best_scores_g)\n",
    "# print(results_scores)\n",
    "# cv_df = pd.DataFrame(results_scores[0])\n",
    "# mask = (\n",
    "#     (cv_df['param_logisticregression__C'] == 0.1) &\n",
    "#     (cv_df['param_logisticregression__l1_ratio'] == 0.3) &\n",
    "#     (cv_df['param_logisticregression__class_weight'] == 'balanced')\n",
    "# )\n",
    "# mean_test_score = cv_df.loc[mask, 'mean_test_score'].iloc[0]\n",
    "# print(f'C 0.1, l1 0.3: {mean_test_score}')\n",
    "\n",
    "# cv_df = pd.DataFrame(results_scores[1])\n",
    "# mask = (\n",
    "#     (cv_df['param_logisticregression__C'] == 0.1) &\n",
    "#     (cv_df['param_logisticregression__l1_ratio'] == 0.9) &\n",
    "#     (cv_df['param_logisticregression__class_weight'] == 'balanced')\n",
    "# )\n",
    "# mean_test_score = cv_df.loc[mask, 'mean_test_score'].iloc[0]\n",
    "# print(f'C 0.1, l1 0.9: {mean_test_score}')\n",
    "\n",
    "# print(results_model)\n",
    "\n",
    "# our best hyperparameters are:\n",
    "# C = 0.1, l1_ratio = 0.7\n",
    "# class_weight = balanced\n",
    "# shuffling = group\n",
    "# score = 0.382426793855901"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f92f0",
   "metadata": {},
   "source": [
    "##### cross validation on XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d300c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "RANDOM_STATE = 1\n",
    "# sample 5% for training\n",
    "SAMPLE_PROP = 0.05\n",
    "# encode as numbers for xgboost \n",
    "y = target[keep_rows]\n",
    "le = LabelEncoder()\n",
    "y = pd.DataFrame(le.fit_transform(y))\n",
    "\n",
    "X = trees[keep_rows].drop(drop_cols_set, axis=1)\n",
    "groups = trees[keep_rows][group]\n",
    "## hold out a test set by groups\n",
    "gss_test = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]\n",
    "## sample 10% for cross validation\n",
    "X_sub, _, y_sub, _, groups_sub, _ = train_test_split(\n",
    "    X_train, y_train, groups_train,\n",
    "    train_size=SAMPLE_PROP,\n",
    "    stratify=y_train,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# get weights\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_sub\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd1727c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   0.6s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.7s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.5s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   0.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.9s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   2.5s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.2s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   2.2s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   3.2s\n",
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   0.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.4s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.0s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.0s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.7s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.3s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.3s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   3.4s\n"
     ]
    }
   ],
   "source": [
    "# testing using XGBoost\n",
    "random_states = [1,99]\n",
    "results_scores_xg = []\n",
    "results_best_scores_xg = []\n",
    "results_params_xg = []\n",
    "results_model_xg = []\n",
    "for rs in random_states:\n",
    "    gss = GroupShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = xgb.XGBClassifier()\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "            'xgbclassifier__learning_rate': [0.1],\n",
    "            'xgbclassifier__max_depth': [3, 5, 7],\n",
    "            'xgbclassifier__n_jobs': [-1],\n",
    "            'xgbclassifier__random_state': [rs],\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X_sub, \n",
    "             y_sub, \n",
    "             groups=groups_sub,\n",
    "             xgbclassifier__sample_weight=sample_weights)\n",
    "    results_params_xg.append(grid.best_params_)\n",
    "    results_scores_xg.append(grid.cv_results_)\n",
    "    best_idx = grid.best_index_\n",
    "    best_val_score = grid.cv_results_['mean_test_score'][best_idx]\n",
    "    results_best_scores_xg.append(best_val_score)\n",
    "    results_model_xg.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"xgbclassifier__learning_rate\": 0.1,\n",
      "        \"xgbclassifier__max_depth\": 7,\n",
      "        \"xgbclassifier__n_estimators\": 300,\n",
      "        \"xgbclassifier__n_jobs\": -1,\n",
      "        \"xgbclassifier__random_state\": 1\n",
      "    },\n",
      "    {\n",
      "        \"xgbclassifier__learning_rate\": 0.1,\n",
      "        \"xgbclassifier__max_depth\": 7,\n",
      "        \"xgbclassifier__n_estimators\": 100,\n",
      "        \"xgbclassifier__n_jobs\": -1,\n",
      "        \"xgbclassifier__random_state\": 99\n",
      "    }\n",
      "]\n",
      "[np.float64(0.4084642110225578), np.float64(0.3817579157682778)]\n"
     ]
    }
   ],
   "source": [
    "print(dumps(results_params_xg, indent=4))\n",
    "print(results_best_scores_xg)\n",
    "\n",
    "# best params are\n",
    "# max_depth = 7\n",
    "# n_estimators = 300\n",
    "# using Group split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f941029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   0.6s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.1s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.6s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   0.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.5s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   2.1s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.0s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   1.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=1; total time=   2.6s\n",
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   0.7s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.2s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.8s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.1s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.5s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.2s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.0s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   1.9s\n",
      "[CV] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300, xgbclassifier__n_jobs=-1, xgbclassifier__random_state=99; total time=   2.7s\n"
     ]
    }
   ],
   "source": [
    "# testing using XGBoost WITHOUT Group Splitting \n",
    "random_states = [1,99]\n",
    "results_scores_xg_ss = []\n",
    "results_best_scores_xg_ss = []\n",
    "results_params_xg_ss = []\n",
    "results_model_xg_ss = []\n",
    "for rs in random_states:\n",
    "    gss = StratifiedShuffleSplit(n_splits=1,random_state=rs)\n",
    "    algo = xgb.XGBClassifier()\n",
    "    pipe = make_pipeline(preprocessor,algo)\n",
    "    param_grid = {\n",
    "            'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "            'xgbclassifier__learning_rate': [0.1],\n",
    "            'xgbclassifier__max_depth': [3, 5, 7],\n",
    "            'xgbclassifier__n_jobs': [-1],\n",
    "            'xgbclassifier__random_state': [rs],\n",
    "            }\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro',\n",
    "        cv=gss,\n",
    "        verbose=2,\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    grid.fit(X_sub, \n",
    "             y_sub,\n",
    "             xgbclassifier__sample_weight=sample_weights)\n",
    "    results_params_xg_ss.append(grid.best_params_)\n",
    "    results_scores_xg_ss.append(grid.cv_results_)\n",
    "    best_idx = grid.best_index_\n",
    "    best_val_score = grid.cv_results_['mean_test_score'][best_idx]\n",
    "    results_best_scores_xg_ss.append(best_val_score)\n",
    "    results_model_xg_ss.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0723a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"xgbclassifier__learning_rate\": 0.1,\n",
      "        \"xgbclassifier__max_depth\": 7,\n",
      "        \"xgbclassifier__n_estimators\": 300,\n",
      "        \"xgbclassifier__n_jobs\": -1,\n",
      "        \"xgbclassifier__random_state\": 1\n",
      "    },\n",
      "    {\n",
      "        \"xgbclassifier__learning_rate\": 0.1,\n",
      "        \"xgbclassifier__max_depth\": 7,\n",
      "        \"xgbclassifier__n_estimators\": 300,\n",
      "        \"xgbclassifier__n_jobs\": -1,\n",
      "        \"xgbclassifier__random_state\": 99\n",
      "    }\n",
      "]\n",
      "[np.float64(0.42164081542427595), np.float64(0.4105136125596484)]\n"
     ]
    }
   ],
   "source": [
    "print(dumps(results_params_xg_ss, indent=4))\n",
    "print(results_best_scores_xg_ss)\n",
    "\n",
    "# best params are\n",
    "# max_depth = 7\n",
    "# n_estimators = 300\n",
    "# using Stratified split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381767c",
   "metadata": {},
   "source": [
    "##### Try `xgboost` models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xg group split: 0.39001143285292533\n",
      "xg stratify split: 0.39001143285292533\n"
     ]
    }
   ],
   "source": [
    "# train a bigger model\n",
    "\n",
    "xg_model = results_model_xg[0]\n",
    "test_score_xg = fbeta_score(y_test, xg_model.predict(X_test), beta=1, average='macro')\n",
    "print(f'xg group split: {test_score_xg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xg_ss_model = results_model_xg_ss[0]\n",
    "test_score_xg_ss = fbeta_score(y_test, xg_ss_model.predict(X_test), beta=1, average='macro')\n",
    "print(f'xg stratify split: {test_score_xg_ss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7addbada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree_census",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
